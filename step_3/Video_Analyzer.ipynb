{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3779b9-f36f-4f18-a933-c36b614644d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import requests\n",
    "import io\n",
    "import glob, os, sys, time, uuid\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "from video_indexer import VideoIndexer\n",
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from azure.cognitiveservices.vision.face.models import TrainingStatusType\n",
    "from msrest.authentication import CognitiveServicesCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199e7e97-f0f8-4059-bde0-c5974bf35360",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = \"4fe196a0811c42cbbd581c45e87a65d7\"\n",
    "ENDPOINT = \"https://face-rtw-e2.cognitiveservices.azure.com/\"\n",
    "\n",
    "face_client = FaceClient(ENDPOINT, CognitiveServicesCredentials(KEY))\n",
    "\n",
    "face_client.api_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6b5416-b643-49f0-80db-16bbdb46232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'SUBSCRIPTION_KEY': '9842b344d288408e821ccd0bb3663003',\n",
    "    'LOCATION': 'trial',\n",
    "    'ACCOUNT_ID': '8ed8e2db-9516-4b89-ab8c-29662c57f6c8'\n",
    "}\n",
    "\n",
    "video_analysis = VideoIndexer(\n",
    "    vi_subscription_key=CONFIG['SUBSCRIPTION_KEY'],\n",
    "    vi_location=CONFIG['LOCATION'],\n",
    "    vi_account_id=CONFIG['ACCOUNT_ID']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c95cd3-b7ed-4eef-8768-12b88ddf2b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_analysis.check_access_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b5c3f1-745d-4b78-a893-1d62edef56be",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id = '9e9c7becca'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a704f0d-7f32-4b03-9f45-15403e01f3c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_analysis.get_video_info(video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd975bf-a277-473b-a524-80f30294c17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = video_analysis.get_video_info(video_id, video_language='English')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284ae79a-fa10-4658-a875-70f5f5003cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(info['videos'][0]['insights']['faces'][0]['thumbnails']):\n",
    "    print(\"We found {} faces in this video.\".format(str(len(info['videos'][0]['insights']['faces'][0]['thumbnails']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576b7390-46d1-40ec-9a6b-09060eb484d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "info['videos'][0]['insights']['faces'][0]['thumbnails']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d8c0ff-d559-4c88-a4b8-ac91198bb583",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "img_raw = []\n",
    "img_strs = []\n",
    "for each_thumb in info['videos'][0]['insights']['faces'][0]['thumbnails']:\n",
    "    if 'fileName' in each_thumb and 'id' in each_thumb:\n",
    "        file_name = each_thumb['fileName']\n",
    "        thumb_id = each_thumb['id']\n",
    "        img_code = video_analysis.get_thumbnail_from_video_indexer(video_id,  thumb_id)\n",
    "        img_strs.append(img_code)\n",
    "        img_stream = io.BytesIO(img_code)\n",
    "        img_raw.append(img_stream)\n",
    "        img = Image.open(img_stream)\n",
    "        images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eed809d-7d9f-4607-a75c-fcf60665fd77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for img in images:\n",
    "    print(img.info)\n",
    "    plt.figure()\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a42c75-1f20-4b63-b3aa-e13dd6b3fb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for img in images:\n",
    "    print(type(img))\n",
    "    img.save('../material_preparation_step/digital_id_template/faces/human-face' + str(i) + '.jpg')\n",
    "    i= i+ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f495a77b-a28d-4178-a8fc-6f16a47ece5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyframes = []\n",
    "for shot in info[\"videos\"][0][\"insights\"][\"shots\"]:\n",
    "    for keyframe in shot[\"keyFrames\"]:\n",
    "        keyframes.append(keyframe[\"instances\"][0]['thumbnailId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48655b44-ee92-49dd-bfec-a1b7c9e8b406",
   "metadata": {},
   "outputs": [],
   "source": [
    "for keyframe in keyframes:\n",
    "    img_str = video_analysis.get_thumbnail_from_video_indexer(video_id,  keyframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d135c0bf-a0a3-4515-8abd-0613e7c72575",
   "metadata": {},
   "outputs": [],
   "source": [
    "info['summarizedInsights']['sentiments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c48b8b-ce82-4d76-a0e6-d8aa98e62cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "info['summarizedInsights']['emotions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d41c34-57d0-480d-8e7d-93d664f3912c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aee119-7e91-4206-9d66-8881cd859286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afe37352-4d15-4891-a7d9-4f26b3387dfc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68772525-9c3f-493c-8b2d-5bed11df0bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSON_GROUP_ID = str(uuid.uuid4())\n",
    "person_group_name = 'person-avkash'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c967ecb-3943-4a5c-b970-d3bec5dafc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_person_group(client, person_group_id, pgp_name):\n",
    "    print('Create and build a person group...')\n",
    "    # Create empty Person Group. Person Group ID must be lower case, alphanumeric, and/or with '-', '_'.\n",
    "    print('Person group ID:', person_group_id)\n",
    "    client.person_group.create(person_group_id = person_group_id, name=pgp_name)\n",
    "\n",
    "    # Create a person group person.\n",
    "    human_person = client.person_group_person.create(person_group_id, pgp_name)\n",
    "    # Find all jpeg human images in working directory.\n",
    "    human_face_images = [file for file in glob.glob('../material_preparation_step/digital_id_template/faces/*') if file.startswith(\"human-face\")]\n",
    "\n",
    "    # Add images to a Person object\n",
    "    for image_p in human_face_images:\n",
    "        with open(image_p, 'rb') as w:\n",
    "            client.person_group_person.add_face_from_stream(person_group_id, human_person.person_id, w)\n",
    "\n",
    "    # Train the person group, after a Person object with many images were added to it.\n",
    "    client.person_group.train(person_group_id)\n",
    "\n",
    "    # Wait for training to finish.\n",
    "    while (True):\n",
    "        training_status = client.person_group.get_training_status(person_group_id)\n",
    "        print(\"Training status: {}.\".format(training_status.status))\n",
    "        if (training_status.status is TrainingStatusType.succeeded):\n",
    "            break\n",
    "        elif (training_status.status is TrainingStatusType.failed):\n",
    "            client.person_group.delete(person_group_id=PERSON_GROUP_ID)\n",
    "            sys.exit('Training the person group has failed.')\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d9fc75-7aee-4ad8-83c4-d9b5995c2dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    build_person_group(face_client, PERSON_GROUP_ID, person_group_name)\n",
    "except Exception as e:\n",
    "    print(e.response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d009751-a69f-4ced-afec-248bb5bc1998",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Detect all faces in query image list, then add their face IDs to a new list.\n",
    "'''\n",
    "def detect_faces(client, query_images_list):\n",
    "    print('Detecting faces in query images list...')\n",
    "\n",
    "    face_ids = {} # Keep track of the image ID and the related image in a dictionary\n",
    "    for image_name in query_images_list:\n",
    "        image = open(image_name, 'rb') # BufferedReader\n",
    "        print(\"Opening image: \", image.name)\n",
    "        time.sleep(5)\n",
    "\n",
    "        # Detect the faces in the query images list one at a time, returns list[DetectedFace]\n",
    "        faces = client.face.detect_with_stream(image)  \n",
    "\n",
    "        # Add all detected face IDs to a list\n",
    "        for face in faces:\n",
    "            print('Face ID', face.face_id, 'found in image', os.path.splitext(image.name)[0]+'.jpg')\n",
    "            # Add the ID to a dictionary with image name as a key.\n",
    "            # This assumes there is only one face per image (since you can't have duplicate keys)\n",
    "            face_ids[image.name] = face.face_id\n",
    "\n",
    "    return face_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd1cb1-df95-408d-846d-c9f2b3b6b952",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = [file for file in glob.glob('/Users/rwhitcom/Documents/ai_engineer_nanodegree/automated_passenger_boarding_kiosk/material_preparation_step/digital_id_template/faces/*')]\n",
    "test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efa05af-b43d-4847-99c0-0941a1b07b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = detect_faces(face_client, test_images)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9dfe66-cdff-4a11-9a2c-67d6b8bb96af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2461213c-0286-4efc-99ec-a61373c17f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification example for faces of the same person.\n",
    "verify_result = face_client.face.verify_face_to_face(ids['/Users/rwhitcom/Documents/ai_engineer_nanodegree/automated_passenger_boarding_kiosk/material_preparation_step/digital_id_template/faces/avkash.png'], ids['/Users/rwhitcom/Documents/ai_engineer_nanodegree/automated_passenger_boarding_kiosk/material_preparation_step/digital_id_template/faces/extracted_avkash.png'])\n",
    "if verify_result.is_identical:\n",
    "    print(\"Faces are of the same (Positive) person, similarity confidence: {}.\".format(verify_result.confidence))\n",
    "else:\n",
    "    print(\"Faces are of different (Negative) persons, similarity confidence: {}.\".format(verify_result.confidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e005f8f7-44dc-4f76-8388-2017b21c50ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_in_cell(face_url):\n",
    "    response = requests.get(face_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71feccc-6615-4d41-96da-8179c5cfc73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_source_url = 'https://raw.githubusercontent.com/udacity/cd0461-building-computer-vision-solutions-with-azure-exercises/main/resources/ca-dl-sample.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8f0f24-b23b-498c-9c1d-d83e3771cf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_in_cell(dl_source_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0971dc1a-aaa9-4125-84c5-4721b8b89573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99c2190-53bf-42b2-99ec-664fb68623c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
